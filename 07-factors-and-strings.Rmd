# Factors and Joins {#seminar07}

```{r message=FALSE, warning=FALSE, include=FALSE}
library(tidyverse)
```

Let us start with a "warm up" exercise that will require combining various things that you already learned. Download [persistence.csv](data/persistence.csv) file (remember, Chrome/Edge browsers may change the extension to _.xls_, just rename it back to _.csv_) and put it into _data_ subfolder in your seminar project folder. This is data from a Master thesis project by Kristina Burkel, published as an article in [Attention, Perception, & Psychophysics](http://link.springer.com/10.3758/s13414-019-01954-7). The work investigated how change in object's shape affected perceptual stability during brief interruptions (50 ms blank intervals). The research question was which of other two history effects working longer time scales will the observed dependence match and, wherefore, which history effect are likely to be produced by the same or shared neuronal representations of 3D rotation. Grab the [exercise notebook](notebooks/Seminar 07.Rmd) before we start.

## Recap
In the first exercise, I want you to implement the actual analysis performed in the paper.

1. [Load](#readr) the data in a table. Name of the variable is up to you. Typically, I use names like `data`, `reports`, `results`, etc. Don't forget to specify columns' type.
2. Exclude `filename` column (it duplicates `Participant` and `Session` columns).
3. Compute a new variable `SameResponse` which is `TRUE` when `Response1` and `Response2` match each other (in the experiment, that means that an object was rotating in the same direction before and after the intervention).
4. For every combination of `Participant`, `Prime` and `Probe` compute proportion of same responses.
5. Plot the results with `Probe` variable on x-axis, proportion of same responses on y-axis, and use `Prime` to facet plots. Use box plots (or violin plots) to visualize the data. Try adding color, labels, etc. to make plots look nice.

Your final plot should look something like this
```{r echo=FALSE, fig.align='center'}
results <- read_csv("data/persistence.csv", 
                    col_types = cols(filename = col_character(),
                         Participant = col_character(),
                         Session = col_character(),
                         Block = col_double(),
                         Trial = col_double(),
                         OnsetDelay = col_double(),
                         Bias = col_character(),
                         Prime = col_character(),
                         Probe = col_character(),
                         Response1 = col_character(),
                         Response2 = col_character(),
                         RT1 = col_double(),
                         RT2 = col_double()))

results %>%
  select(-filename) %>%
  mutate(SameResponse = Response1 == Response2)  %>%
  group_by(Participant, Prime, Probe) %>%
  summarise(Psame = mean(SameResponse), .groups="drop") %>%
  
  ggplot(aes(x=Probe, y=Psame, color=Probe)) + 
  geom_boxplot() + 
  facet_wrap(.~Prime)
```

::: {.infobox .practice}
Do exercise 1.
:::

When you examine the plot, you can see some sort of non-monotonic dependence with a dip for `"stripes-2"` and `"stripes-4"` objects. In reality, the dependence is monotonic, it is merely the order of values on the x-axis that is wrong. The correct order, based on the area of an object covered with dots, is `"heavy poles sphere"`, `"stripes-8"`, `"stripes-4"`, `"stripes-8"`. Both `Prime` and `Probe` are _ordinal_ variables called _factors_ in R. Thus, to fix the order and to make object names a bit better looking, we must figure out how to work with factors in R.

## Factors {#factors}
Factors are categorical variables, thus variables that have a finite fixed and known set of possible values. They can be either _nominal_ (cannot be ordered) or _ordinal_ (have a specific order to them). An example of the former is the drive train (`drv`) variable in [mpg](https://ggplot2.tidyverse.org/reference/mpg.html) table. There is a finite set of possible values (`"f"` for front-wheel drive, `"r"` for rear wheel drive, and `"4"` for a four-wheel drive) but ordering them makes no sense. An example of an ordinal variable is a Likert scale that has a finite set of possible responses (for example, `"disagree"`, `"neither agree, nor disagree"`, `"agree"`) and they do a fix specific order to them (participant's support for a statement is progressively stronger so that `"disagree"` < `"neither agree, nor disagree"` < `"agree"`).

**Important side-note:** remember, ordinal variables are not metric, so you cannot treat them the same way. For example, you cannot compute a mean response because computation of the mean assumes, among other things, that all factors are equidistant from each other (i.e., `("agree" - "neither agree, nor disagree") == ("neither agree, nor disagree" - "disagree")` and that `2 * ("agree" - "neither agree, nor disagree") == ("agree" - "disagree")`). In reality, most likely this is not the case, particularly when you have more response options (people are typically vary of using extreme values). And, to make things worse, this differences between individual levels will be most probably different for different participants. This issue is not so much about data analysis per se (although, not computing mean response is a good start), but rather about using a correct statistical procedure to analyze ordinal data. If you work with ordinal data (and, if you in psychology then you almost certainly use Likert scale), I strongly recommend reading [Analyzing ordinal data with metric models: What could possibly go wrong?](https://www.sciencedirect.com/science/article/abs/pii/S0022103117307746) paper by Liddell and Kruschke (as of writing, a PDF is freely available at [hbiostat.org](http://hbiostat.org/papers/ordinal/lid18ana.pdf)).

**Another important side-note:** computers are golems, not oracles. Having read the previous paragraph, you may ask yourself: _What if I convert scales to numbers, so that `"disagree"=1`, `"neither agree, nor disagree"=2`, and `"agree"=3` and compute mean of numbers?_. Yep, you can do that! _Will I get some "average" numbers, if I compute mean of these numbers?_ Yes, you will! _Will statistics police knock on my door, if I do that?_ No, it wont! _So, all is good?_ Nope. The fact that computer did not crash and did spit out some numbers, does not mean that these numbers mean anything. Computers are [golems](https://en.wikipedia.org/wiki/Golem), not [oracles](https://en.wikipedia.org/wiki/Oracle). They will perform a computation you've asked for even if it makes no sense. Computers don't know what you are doing, why are you doing it, and whether it is a valid approach. Computers don't care if you are treating ordinal data as metric or using ANOVA on proportional data. They will carry out the computation and will give the result. Unfortunately, it is _on you_ to know whether results are valid or are even interpretable. The worst case scenario is using a complex analysis without understanding how it actually works and which assumptions it uses. You will have no way of knowing whether your results are valid but might hope that "computer knows what it is doing". This is when you start having a problem because you are flying blind without even realizing that. To summarize, _you_ must know that what you are doing is valid and correct, not the computer!

Now that I've vented my feelings about using inappropriate analysis procedures, let's get back to factors! You can convert _any_ variable to a factor using [factor()](https://stat.ethz.ch/R-manual/R-devel/library/base/html/factor.html) or `as.factor()` functions. The latter is a more limited version of the former, so, below, I will only use `factor()`. When you convert a variable (a vector) to factor, R:

1. figures out all [unique](https://stat.ethz.ch/R-manual/R-devel/library/base/html/unique.html) values in this vector
2. sorts them in an ascending order
3. assigns each value an index ("level")
4. uses the actual value as a "label".

Here is an example of this sequence: there four levels sorted alphabetically.
```{r}
letters <- c("C", "A", "D", "B", "A", "B")
letters_as_factor <- factor(letters)
letters_as_factor
```

You can extracts [levels](https://stat.ethz.ch/R-manual/R-devel/library/base/html/levels.html) of a factor variable by using the function with this name
```{r}
levels(letters_as_factor)
```

You can specify the order of levels either during the `factor()` conversion call or later using [forcats](https://forcats.tidyverse.org/) (more on that later). For example, if we want to have levels in the reverse order we specify it via `levels` parameter. Note the opposite order of levels.
```{r}
letters <- c("C", "A", "D", "B", "A", "B")
letters_as_factor <- factor(letters, levels = c("D", "C", "B", "A"))
letters_as_factor
```

We can also specify `labels` of individual labels instead of using values themselves. Note that labels must
```{r}
responses <- c(1, 3, 2, 2, 1, 3)
responses_as_factor <- factor(responses, labels = c("negative", "neutral", "positive"))
responses_as_factor
```

You can see _indexes_ that were assigned to each level by converting `letter_as_factor` to a numeric vector. In this case, R throws away labels and returns indexes.
```{r}
as.numeric(letters_as_factor)
```

However, be careful when level labels are numbers. In the example below, you might be expecting that `as.numeric(tens)` should give you `[20, 40, 30]` but these are labels! If you need to convert labels to numbers, you have to do it in two steps `as.numeric(as.character(tens))`: `as.character()` turns factors to strings (using labels) and `as.numeric()` converts those labels to numbers (if that conversion can work).
```{r}
tens <- factor(c(20, 40, 30))
print(tens)
print(as.numeric(tens))
print(as.numeric(as.character(tens)))
```

For the next exercise, copy-paste the code from exercise #1 and alter it so the labels are `"sphere"` (for `"heavy poles sphere"`), `"quad band"` (for `"stripes-8"`), `"dual band"` (`"stripes-4"`), `"single band"` (for `"stripes-2"`) and levels are be in that order. Your plot should look something like this.

```{r echo=FALSE, fig.align='center'}
results %>%
  select(-filename) %>%
  mutate(SameResponse = Response1 == Response2)  %>%
  mutate(Prime = factor(Prime, 
                        levels= c("heavy poles sphere", "stripes-8", "stripes-4", "stripes-2"),
                        labels = c("sphere", "quad band", "dual band", "single band")),
         Probe = factor(Probe, 
                        levels= c("heavy poles sphere", "stripes-8", "stripes-4", "stripes-2"),
                        labels = c("sphere", "quad band", "dual band", "single band")),) %>%
  group_by(Participant, Prime, Probe) %>%
  summarise(Psame = mean(SameResponse), .groups="drop") %>%
  
  ggplot(aes(x=Probe, y=Psame, color=Probe)) + 
  geom_boxplot() + 
  facet_wrap(.~Prime)
```

::: {.infobox .practice}
Do exercise 2.
:::

## Forcats {#forcats}
Tidyverse has a package [forcats](https://forcats.tidyverse.org/)^[The package's name is anagram of _factors_.] that makes working with factors easier. For example, it allows to reorder levels either by hand ([fct_relevel()](https://forcats.tidyverse.org/reference/fct_relevel.html)) or automatically based on the [order of appearance](https://forcats.tidyverse.org/reference/fct_inorder.html), [frequency](https://forcats.tidyverse.org/reference/fct_inorder.html), [value of other variable](https://forcats.tidyverse.org/reference/fct_reorder.html), etc. It also gives you flexible tool to changes labels either by hand ([fct_recode()](https://forcats.tidyverse.org/reference/fct_recode.html)), by [lumping](https://forcats.tidyverse.org/reference/fct_lump.html)  some levels together, by [anonymising them](https://forcats.tidyverse.org/reference/fct_anon.html), etc. In my work, I mostly use reordering ([fct_relevel()](https://forcats.tidyverse.org/reference/fct_relevel.html)) and renaming ([fct_recode()](https://forcats.tidyverse.org/reference/fct_recode.html)) of factors by hand. These two functions that you will need to use in exercise #3. However, if you find yourself working with factors, it is a good idea to check [forcats](https://forcats.tidyverse.org/) functions to see whether they can make your life easier.

To reorder factor by hand, you simply state the desired order of factors, similar to they way you specify this via `levels=` parameters in `factor()` function. However, in [fct_relevel()](https://forcats.tidyverse.org/reference/fct_relevel.html) you can move only _some_ factors and others are "pushed to the back".
```{r}
letters <- c("C", "A", "D", "B", "A", "B")
letters_as_factor <- factor(letters, levels = c("B", "C", "D", "A"))
print(letters_as_factor)
```

```{r}
# specifying order for ALL levels
letters_as_factor <- fct_relevel(letters_as_factor, "D", "C", "B", "A")
print(letters_as_factor)
```

```{r}
# specifying order for just ONE level, the rest are "pushed back"
# "A" should now be the first level and the rest are pushed back in their original order
letters_as_factor <- fct_relevel(letters_as_factor, "A")
print(letters_as_factor)
```
You can also put a level at the very back, as second level, etc. [fct_relevel()](https://forcats.tidyverse.org/reference/fct_relevel.html) is very flexible, so check reference whenever you use it.

To rename individual levels you use [fct_recode()](https://forcats.tidyverse.org/reference/fct_recode.html) by providing `new = old` pairs of values.
```{r}
letters_as_factor <- factor(c("C", "A", "D", "B", "A", "B"))
letters_as_factor <- fct_recode(letters_as_factor, "_A_" = "A", "_C_" = "C")
print(letters_as_factor)
```
Note that this allows you to merge levels by hand.
```{r}
letters_as_factor <- factor(c("C", "A", "D", "B", "A", "B"))
letters_as_factor <- fct_recode(letters_as_factor, "_AC_" = "A", "_AC_" = "C")
print(letters_as_factor)
```

For exercise #3, redo exercise #2 but using [fct_relevel()](https://forcats.tidyverse.org/reference/fct_relevel.html) and [fct_recode()](https://forcats.tidyverse.org/reference/fct_recode.html). You still need to use `factor()` function to convert `Prime` and `Probe` to factor but do not specify levels and labels. Use [fct_relevel()](https://forcats.tidyverse.org/reference/fct_relevel.html) and [fct_recode()](https://forcats.tidyverse.org/reference/fct_recode.html) inside `mutate()` verbs to reorder and relabel factor values (or, first relabel and then reorder, whatever is more intuitive for you).

::: {.infobox .practice}
Do exercise 3.
:::

## Plotting group averages
Let us keep practicing and extend our analysis to compute and plots averages and 89% confidence interval for each condition (`Prime`×`Probe`) over all participants. You already know how to compute an average. To compute confidence interval, you need to compute its lower and upper limits separate. For this, you need to compute [quantiles](https://en.wikipedia.org/wiki/Quantile). A quantile for 0.1 (10%) tells you a value, so that 10% of all values in the vector are below it, the quantile of 0.9 (90%) means that only 10% of values are above it (or 90% are below). So, an 80% confidence intervals includes values that are between 10% and 90% or, alternatively, between 0.1 and 0.9 quantiles.
```{r echo=FALSE, fig.align='center', out.width="100%"}
quantile_example <- 
  tibble(x = 0:50,
         Values = case_when(x < quantile(x, 0.1) ~ "10% of values are SMALLER (to the left of this line)",
                            x > quantile(x, 0.9) ~ "10% of values are LARGER (to the right of this line)",
                            TRUE ~ "80% of values are between the lines")) %>%
  mutate(Values = fct_relevel(Values, "10% of values are LARGER (to the right of this line)", "80% of values are between the lines"))

ggplot(data=quantile_example, aes(x=x, y=1, color=Values)) + 
  geom_point() + 
  geom_vline(xintercept = quantile(quantile_example$x, c(0.1, 0.9))) +
  labs(subtitle = "80% confidence interval")
```
To compute this, R has function [quantile()](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/quantile.html).
```{r}
x <- 0:50
quantile(x, 0.1)
```
Use preprocessing code from exercise #3 but, once you computed proportion per `Participant`×`Prime`×`Probe`, you need to group data over `Prime`×`Probe` to compute average performance across observers plus the 89% confidence interval (think about what are the lower and upper limits for 89% CI). Then, use [geom_point()](https://ggplot2.tidyverse.org/reference/geom_point.html) plus [geom_line()](https://ggplot2.tidyverse.org/reference/geom_path.html) to plot the mean response and [geom_errorbar()](https://ggplot2.tidyverse.org/reference/geom_linerange.html) to plot 89% CI (you will need to map the two variable you computed to `ymin` and `ymax` properties). The plot should like like this (hint, drop color mapping and map `Prime` to `group` property).

```{r echo=FALSE, fig.align='center'}
results %>%
  select(-filename) %>%
  mutate(SameResponse = Response1 == Response2)  %>%
  mutate(Prime = factor(Prime, 
                        levels= c("heavy poles sphere", "stripes-8", "stripes-4", "stripes-2"),
                        labels = c("sphere", "quad band", "dual band", "single band")),
         Probe = factor(Probe, 
                        levels= c("heavy poles sphere", "stripes-8", "stripes-4", "stripes-2"),
                        labels = c("sphere", "quad band", "dual band", "single band")),) %>%
  group_by(Participant, Prime, Probe) %>%
  summarise(Psame = mean(SameResponse), .groups="drop") %>%
  
  group_by(Prime, Probe) %>%
  summarise(Pavg = mean(Psame), 
            CIlower = quantile(Psame, (1-0.89)/2),
            CIupper = quantile(Psame, 1-(1-0.89)/2),
            .groups="drop") %>%
  
  ggplot(aes(x=Probe, y=Pavg, ymin=CIlower, ymax=CIupper, group=Prime)) + 
  geom_point() + 
  geom_line() +
  geom_errorbar() +
  facet_wrap(.~Prime)
```

::: {.infobox .practice}
Do exercise 4.
:::

Tweak code from exercise 4 to plot all lines on the same plot and use color property to distinguish between different primes.
```{r echo=FALSE, fig.align='center'}
results %>%
  select(-filename) %>%
  mutate(SameResponse = Response1 == Response2)  %>%
  mutate(Prime = factor(Prime, 
                        levels= c("heavy poles sphere", "stripes-8", "stripes-4", "stripes-2"),
                        labels = c("sphere", "quad band", "dual band", "single band")),
         Probe = factor(Probe, 
                        levels= c("heavy poles sphere", "stripes-8", "stripes-4", "stripes-2"),
                        labels = c("sphere", "quad band", "dual band", "single band")),) %>%
  group_by(Participant, Prime, Probe) %>%
  summarise(Psame = mean(SameResponse), .groups="drop") %>%
  
  group_by(Prime, Probe) %>%
  summarise(Pavg = mean(Psame), 
            CIlower = quantile(Psame, (1-0.89)/2),
            CIupper = quantile(Psame, 1-(1-0.89)/2),
            .groups="drop") %>%
  
  ggplot(aes(x=Probe, y=Pavg, ymin=CIlower, ymax=CIupper, color=Prime, group=Prime)) + 
  geom_point() + 
  geom_line() +
  geom_errorbar()
```
::: {.infobox .practice}
Do exercise 5.
:::

## Looking at similarity
From the plots above, you get a sense that identities of the probe and prime (objects before and after the interruption) matter. Single band appears to be the poorest prime (its line is lowest) and probe (its dots are lower than the rest). Conversely, sphere is an excellent prime (line at the top) and probe (dots are very high). However, a different study, which used same four objects, showed that a similar looking history effect but for longer interruptions (1000 ms rather than 50 ms) was modulated by objects similarity. Let us check that hypothesis by computing a rough difference measure. It will assume that their difference is proportional to the absolute "distance" between them on x-axis in the above plot^[This measure assumes metric distance, which is a very strong assumption.]. E.g., distance between a sphere and a sphere is 0, but between sphere and quad-band or single-band and dual-band is 1. Difference between sphere and dual-band is 2, etc. You can compute it by converting _factor_ variables `Prime` and `Probe` to integers (this assumes that levels are in the correct order). Then, you can compute the [absolute difference](https://stat.ethz.ch/R-manual/R-devel/library/base/html/MathFun.html) between those indexes and store it as a new column (e.g. `Difference`). Next, group by `Difference` and `Participant` to compute average probability of the same response. Your plot should look like this (you will need to map `Difference` on `group` to get four box plots rather than one).

```{r echo=FALSE, fig.align='center'}
results %>%
  select(-filename) %>%
  mutate(SameResponse = Response1 == Response2)  %>%
  mutate(Prime = factor(Prime, 
                        levels= c("heavy poles sphere", "stripes-8", "stripes-4", "stripes-2"),
                        labels = c("sphere", "quad band", "dual band", "single band")),
         Probe = factor(Probe, 
                        levels= c("heavy poles sphere", "stripes-8", "stripes-4", "stripes-2"),
                        labels = c("sphere", "quad band", "dual band", "single band")),) %>%
  group_by(Participant, Prime, Probe) %>%
  summarise(Psame = mean(SameResponse), .groups="drop") %>%
  
  ungroup() %>%
  mutate(iPrime = as.integer(Prime),
         iProbe = as.integer(Probe),
         Difference = abs(iPrime - iProbe)) %>%
  
  group_by(Participant, Difference) %>%
  summarise(Pavg = mean(Psame), 
            CIlower = quantile(Psame, (1-0.89)/2),
            CIupper = quantile(Psame, 1-(1-0.89)/2),
            .groups="drop") %>%
  
  ggplot(aes(x=Difference, y=Pavg, ymin=CIlower, ymax=CIupper, group=Difference)) + 
  geom_boxplot()
```

::: {.infobox .practice}
Do exercise 6.
:::

## Joining tables
Sometimes, different information is stored in separate tables. For example, information on participants' demographics can be stored separately from their responses. The former is the same for all trials and conditions, so it makes little sense to duplicate it. However, for the actual analysis, you need to add this information, merging or, in Tidyverse-speak, [joining](https://dplyr.tidyverse.org/reference/mutate-joins.html) two tables. To join two tables you must specify "key" columns, columns that contain values that will be used to match rows between the tables.

Assume that we have two tables that both have column named `ID` that contains a unique of a participant. For the second table, I use functions [rep()](https://stat.ethz.ch/R-manual/R-devel/library/base/html/rep.html) to repeat each `ID` three times and [runif()](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/Uniform.html) to generate random number from a specific range. Note that we have participant `"D"` in `demographics` but participants `"E"` in `reports`!
```{r}
demographics <- tibble(ID = c("A", "B", "C", "D"),
                       Age = c(20, 19, 30, 22))

knitr::kable(demographics)

reports <- tibble(ID = rep(c("A", "B", "C", "E"), each=2),
                  Report = runif(length(ID), 1, 7))

knitr::kable(reports)
```
 Here, `ID` column will serve as a key to indicate which rows from two columns belong together. _dplyr_ implements four [Mutating joins](https://dplyr.tidyverse.org/reference/mutate-joins.html) which differ in how the two tables are joined, if a key value is missing in one of them. The `inner_join()` only include the rows for which key value is present in **both** tables. In our case, only `"A"`, `"B"`, and `"C"` participants are in both tables, so _inner join_ will discard rows with `"D"` (not present in `reports`) and `"E"` (not present in `demographics`).
```{r}
inner_join(demographics, reports, by="ID") %>%
  knitr::kable()
```
Conversely, `full_join()` will include all rows from both tables but will fill missing values with `NA` (_Not Available_ / _Missing Values_). Thus, it will put `NA` for the `Age` of participant `"E"` and `Report` of participant `"D"`.
```{r}
full_join(demographics, reports, by="ID") %>%
  knitr::kable()
```
The `left_join()` and `right_join()` include all the row from, respectively, left and right (first and second) tables but discard extra keys from the other one. Note that two functions are just mirror opposites, so doing `left_join(demographics, reports, by="ID")` is equivalent (but for order of columns and rows) to `right_join(reports, demographics, by="ID")`.
```{r}
left_join(demographics, reports, by="ID") %>%
  knitr::kable()

right_join(demographics, reports, by="ID") %>%
  knitr::kable()
```

You can also use more than one key. Note in the example below, there are no missing / extra keys, so all four joins will produce the same results, they differ only in how they treat those missing/extra keys.
```{r}
demographics <- tibble(ID = c("A", "B", "A", "B"),
                       Gender = c("M", "F", "F", "M"),
                       Age = c(20, 19, 30, 22))

knitr::kable(demographics)

reports <- tibble(ID = c("A", "B", "A", "B"),
                  Gender = c("M", "F", "F", "M"),
                  Report = runif(length(ID), 1, 7))
knitr::kable(reports)

inner_join(demographics, reports, by=c("ID", "Gender")) %>%
  knitr::kable()
```

Finally, you key columns can be named _differently_ in two tables. In this case, you need to "match" them explicitly.
```{r}
demographics <- tibble(VPCode = c("A", "B", "A", "B"),
                       Sex = c("M", "F", "F", "M"),
                       Age = c(20, 19, 30, 22))

knitr::kable(demographics)

reports <- tibble(ID = c("A", "B", "A", "B"),
                  Gender = c("M", "F", "F", "M"),
                  Report = runif(length(ID), 1, 7))
knitr::kable(reports)

inner_join(demographics, reports, by=c("VPCode"="ID", "Sex"="Gender")) %>%
  knitr::kable()
```

