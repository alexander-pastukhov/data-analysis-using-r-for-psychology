# Grammar of Graphics {#ggplot2}

In previous seminar, you have learned about tables that are the main way of representing data in psychological research and in R. In the following seminars, you will learn how to manipulate the data in these tables: change it, aggregate or transform individual groups of data, use it for statistical analysis. But before that you need to understand how to store your data in the table in the optimal way. First, I will introduce the idea of _tidy data_, the concept that gave [Tidyverse](https://www.tidyverse.org/) its name. Next, we will see how tidy data helps you visualize the relationships between variables. Don't forget to download the [notebook]().

## Tidy data {#tidydata}
The tidy data follows [three rules](https://r4ds.had.co.nz/tidy-data.html):

* variables are in columns,
* observations are in rows,
* values are in cells.

This probably sound very straightforward to the point that you wonder "Can a table not by tidy?" As a matter of fact _a lot_ of typical results of psychological experiments are not tidy. Imagine an experiment where participants rated a face on symmetry, attractiveness, and trustworthiness. Typically (at least in my experience), the data will stored as follows:
```{r echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
widish_df <- 
  tibble(Participant = c(1, 1, 2, 2),
         Face = rep(c("M1", "M2"), 2), 
         Symmetry = c(6, 4, 5, 3),
         Attractiveness = c(4, 7, 2, 7),
         Trustworthiness = c(3, 6, 1, 2))

knitr::kable(widish_df, align="c")
```

This is a very typical table optimized for _humans_. A single row contains all responses about a single face, so it is easy to visually compare responses of individual observers. Often, the table is even wider so that a single row holds all responses from a single observer (in my experience, a lot of online surveys produce data in this format).
```{r echo=FALSE, message=FALSE, warning=FALSE}
wide_df <- 
  tibble(Participant = c(1, 1),
         M1.Symmetry = c(6, 5),
         M1.Attractiveness = c(4, 2),
         M1.Trustworthiness = c(3, 1),
         M2.Symmetry = c(4, 3),
         M2.Attractiveness = c(7, 7),
         M2.Trustworthiness = c(6, 2))

knitr::kable(wide_df, align="c")
```

So, what is wrong with it? Don't we have variables in columns, observations in rows, and values in cells? Not really. You can already see it when comparing the two tables above. The _face_ identity is a variable, however, in the second table it is hidden in column names. Some columns are about face `M1`, other columns are about `M2`, etc. So, if you are interested in analyzing symmetry judgments across all faces and participants, you will need to select all columns that end with `.Symmetry` and figure out a way to extract the face identity from columns' names. Thus, face _is_ a variable but is not a column in the second table. 

Then, what about the first table, which has `Face` as a column, is it tidy? The short answer: Not really but that depends on your goals as well! In the experiment, we collected _responses_ (these are numbers in cells) for different type of _judgments_. The latter are a variable but it is hidden in column names. Thus, a _tidy_ table for this data would be

```{r echo=FALSE, message=FALSE, warning=FALSE}
long_df <- tidyr::pivot_longer(widish_df, 
                               cols=c("Symmetry", "Attractiveness", "Symmetry"),
                               names_to="Judgment",
                               values_to="Response")
knitr::kable(long_df, align="c")
```

This table is (very) tidy and it makes it easy to group data by every different combination of variables (e.g. per face and judgment, per participant and judgment), perform statistical analysis, etc. However, it may not always be the best way to represent the data. For example, if you would like to model `Trustworthiness` using `Symmetry` and `Attractiveness` as predictors, when the first table is more suitable. At the end, the table structure must fit your needs, not the other way around. Still, what you probably want is a _tidy_ table because it is best suited for most things you will want to do with the data and because it makes it easy to transform the data to match your specific needs (e.g., going from the third table to the first one via pivoting).

Most data you will get from experiments will not be tidy. We will spent quite some time in learning how to tidy it up but first let us see how an already tidy data makes it easy to visualize relationships in it.

## ggplot2
[ggplot2](https://ggplot2.tidyverse.org/) package is my main tool for data visualization in R.  ggplot2 tends to make really good looking production-ready plots (this is not a given, a default-looking Matlab plot is, or used to be when I used Matlab, pretty ugly). Hadley Wickham was influenced by works of [Edward Tufte](https://www.edwardtufte.com/tufte/) when developing ggplot2. Although the aesthetic aspect goes beyond our seminar (although, if you are interested, I might make a Christmas-special on that), if you will need to visualize data in the future, I strongly recommend reading Tufte's books. In fact, it is such an informative and aesthetically pleasing experience that I would recommend reading them in any case.

More importantly, ggplot2 uses a grammar-based approach of describing a plot that makes it conceptually different from most other software such as Matlab,  Matplotlib in Python, etc. A plot in _ggplot2_ is described in three parts:

1. Aesthetics: Relationship between data and visual properties that define working space of the plot (which variables map on axes, color, size, fill, etc.).
2. Geometrical primitives that visualize your data (points, lines, error bars, etc.) that are _added_ to the plot.
3. Other properties of the plot (scaling of axes, labels, annotations, etc.) that are _added_ to the plot.

You always need the first one. But you do not need to specify the other two, even though a plot without geometry in it looks very empty. Let us start with a very simple artificial example table below.
```{r echo=FALSE, message=FALSE, warning=FALSE,  fig.align="center"}
library(tidyverse)
simple_tidy_data <- 
  expand.grid(Condition = c("A", "B", "C"), Intensity = 1:8) %>%
  mutate(Response = rnorm(n(), 1, 0.2) - rnorm(n(), as.numeric(as.factor(Condition)), 0.2) * 2 + rnorm(n(), Intensity, 0.4))

knitr::kable(simple_tidy_data)
```

We plot this data by 1) _defining aesthetics_ (mapping `Intensity` on to x-axis, `Response`on y-axis, and `Condition` on color) and 2) _adding_ lines to the plot (note the plus in `+ geom_line()`).
```{r}
ggplot(data=simple_tidy_data, aes(x = Intensity, y = Response, color=Condition)) + 
  geom_line()
```

As I already wrote, technically, we only thing you need to define is aesthetics, so let us not add anything to the plot (drop the `+geom_line()`).
```{r fig.align = 'center'}
ggplot(data=simple_tidy_data, aes(x = Intensity, y = Response, color=Condition))
```
Told you it will look empty and yet you can see _ggplot2_ in action. Notice that axes are labeled and their limits are set. You cannot see the legend (they are not plotted without corresponding geometry) but it is also ready. This is because our initial call specified the most important part: how the individual variables map on various properties even before we told _ggplot2_ which visuals we will use to plot the data. When we specified that x-axis will represent the `Intensity`, ggplot2 figured out the range of values, so it knows _where_ it is going to plot whatever we decide to plot. Points, lines, bar, error bars and what not will span only that range. Same goes for other properties such as color. We wanted _color_ to represent the condition. Again, we may not know what exactly we will be plotting (points, lines?) or even how many different visuals we will be adding to the plot (just lines? points + lines? points + lines + linear fit?) but we do know that whatever visual we add, if it can have color, its color _must_ represent condition for that data point. The beauty of _ggplot2_ is that it analyses your data and figures out how many colors you need and is ready to  apply them _consistently_ to all visuals you will later add. It will ensure that all points, bars, lines, etc. will have consistent coordinates scaling, color-, size-, fill-mapping that are the same across the entire plot. This may sound trivial but typically (e.g., Matlab, Matplotlib), it is _your_ job to make sure that all these properties match and that they represent the same value across all visual elements. And this is a pretty tedious job, particularly when you decide to change your mappings and have to redo all individual components by hand. In _ggplot2_, this dissociation between mapping and visuals means you can tinker with one of them at a time. E.g. keep the visuals but change grouping or see if effect of condition is easier to see via line type, size or shape of the point? Or you can keep the mapping and see whether adding another visual will make the plot easier to understand. Note that some mapping also _groups_ your data, so when you use group-based visual information (e.g. a linear regression line) it will know what data belongs together and so will perform this computation per group.

Let us see how you can keep the relationship mapping but add more visuals. Let us add both lines and points.
```{r fig.align = 'center'}
ggplot(data=simple_tidy_data, aes(x = Intensity, y = Response, color=Condition)) + 
  geom_line() +
  geom_point() # this is new!
```

In the plot above, we _kept_ the relationship between variables and properties but said "Oh, and throw in some points please". And ggplot2 knows how to add the points so that they appear at proper location and in proper color. But we want more!
```{r fig.align = 'center'}
ggplot(data=simple_tidy_data, aes(x = Intensity, y = Response, color=Condition)) + 
  geom_line() +
  geom_point() +
  # a linear regression over all dots in the group
  geom_smooth(method="lm", formula = y ~ x, se=FALSE, linetype="dashed") 
```

Now we added a linear regression line that helps us to better see  the relationship between `Intensity` and `Response`. Again, we simply wished for another visual to be added (`method="lm"` means that we wanted to average data via linear regression with `formula = y ~ x` meaning that we regress y-axis on x-axis with no further covariates, `se=FALSE` means no standard error stripe, `linetype="dashed"` just makes it easier to distinguish from the solid data line).

Or, we can keep the _visuals_ but see whether changing _mapping_ would make it more informative (we need to specify `group=Intensity` as continuous data is not grouped automatically).
```{r fig.align = 'center'}
ggplot(data=simple_tidy_data, aes(x = Condition, y = Response, color=Intensity, group=Intensity)) + 
  geom_line() +
  geom_point() +
  geom_smooth(method="lm", se=FALSE,  formula = y ~ x, linetype="dashed")
```

Or, we can check whether splitting into several plots helps.
```{r fig.align = 'center'}
ggplot(data=simple_tidy_data, aes(x = Intensity, y = Response, color=Condition)) + 
  geom_line() +
  geom_point() +
  geom_smooth(method="lm", formula = y ~ x, se=FALSE, linetype="dashed") +
  facet_grid(. ~ Condition) # makes a separate subplot for each group
```
Again, note that all three plots live on the same scale for x- and y-axis, making them easy to compare (you fully appreciate this magic if you ever struggled with ensuring optimal and consistent scaling by hand in Matlab). I went through so many examples to stress how ggplot allows you to think about the aesthetics of variable mappping _independently_ of the actual visual representation (and vice versa). So now lets us explore _ggplot2_ by doing exercises.

## Visualizing auto efficiency



## Extending ggplot2
What you explored is just a tip of the iceberg. There are 80 (as of 19.11.2020) extensions that you find  at [ggplot2 website](https://exts.ggplot2.tidyverse.org/gallery/). They add more ways to plot your data, more themes, animated plots, etc. If you feel that _ggplot2_ does not have the geometric primitives you need, take a look at the gallery and, most likely, you will find something that fits your bill. 

One package that is _not_ in the gallery is [patchwork](https://patchwork.data-imaginist.com/). It was created "to make it ridiculously simple to combine separate ggplots into the same graphic". It is a bold promise but authors do make good on it. It is probably the easiest way to  combine multiple plots but you can also consider [cowplot](https://github.com/wilkelab/cowplot) and [gridExtra](https://cran.r-project.org/web/packages/gridExtra/index.html) packages.

## Further reading
If plotting data is part of your daily routine, I recommend reading [ggplot2 book](https://ggplot2-book.org/). It gives you an in-depth view of the package and goes through many possibilities that it offers. You may need all of them but I find useful to know that they exists (who knows, I might need them one day). Another book worth reading is [Data Visualization: A Practical Introduction.](https://kieranhealy.org/publications/dataviz/) by Kieran Healy.


## Wrap up
There are many different plotting routines and packages for R but I would recommend to use _ggplot2_ as your main tool. However, that does not mean that it must be your only tool, after all, CRAN is brimming with packages. In particular, _ggplot2_ is built for plotting data from a single tidy table, meaning it is less optimal for plotting data in other cases. E.g., you can use it to combine information from several tidy tables in one plot but things become less automatic and consistent. Similarly, you can plot data which is stored in non-tidy tables or even in individual vectors but that makes it even more convoluted. No package can do everything and _ggplot2_ is no exception. 


